{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmer=WordNetLemmatizer()\n",
    "\n",
    "def load_file(filename):\n",
    "    file = open(filename, 'r', encoding='UTF-8', newline='')\n",
    "    X = []\n",
    "    y = []\n",
    "    for line in file:\n",
    "        split = line.split('\\t')\n",
    "        label = split[1]\n",
    "        review = tokenizer.tokenize(split[0])\n",
    "        review = [lemmer.lemmatize(x.lower()) for x in review]\n",
    "        review = \" \".join(review)\n",
    "        X.append(review)\n",
    "        y.append(label)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_file(\"IMDB-train.txt\")\n",
    "X_dev, y_dev = load_file(\"IMDB-valid.txt\")\n",
    "X_test, y_test = load_file(\"IMDB-test.txt\")\n",
    "\n",
    "y_final_train = np.array(y_train + y_dev)\n",
    "X_final_train = np.array([row for row in X_train] + [row for row in X_dev])\n",
    "\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(ngram_range = (1,2), binary = True)\n",
    "#vectorizer = feature_extraction.text.CountVectorizer(ngram_range = (1,2), binary = True)\n",
    "vectorizer.fit(X_train + X_dev + X_test)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_dev = vectorizer.transform(X_dev)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "X_final_train = vectorizer.transform(X_final_train)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 2)\n",
    "y_dev = np_utils.to_categorical(y_dev, 2)\n",
    "y_test = np_utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "batch: 400 neuron:100 dropout: 0.3\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 507s 34ms/step - loss: 0.5467 - acc: 0.8415\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 514s 34ms/step - loss: 0.0403 - acc: 0.9946\n",
      "10000/10000 [==============================] - 327s 33ms/step\n",
      "\n",
      "acc: 91.08%\n",
      "25000/25000 [==============================] - 826s 33ms/step\n",
      "\n",
      "acc: 90.22%\n",
      "---------------------------------------------------------------------\n",
      "batch: 400 neuron:100 dropout: 0.4\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 502s 33ms/step - loss: 0.5580 - acc: 0.8194\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 498s 33ms/step - loss: 0.0507 - acc: 0.9943\n",
      "10000/10000 [==============================] - 329s 33ms/step\n",
      "\n",
      "acc: 90.95%\n",
      "25000/25000 [==============================] - 791s 32ms/step\n",
      "\n",
      "acc: 90.31%\n",
      "---------------------------------------------------------------------\n",
      "batch: 400 neuron:100 dropout: 0.5\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 530s 35ms/step - loss: 0.5646 - acc: 0.8260\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 460s 31ms/step - loss: 0.0576 - acc: 0.9941\n",
      "10000/10000 [==============================] - 305s 30ms/step\n",
      "\n",
      "acc: 91.13%\n",
      "25000/25000 [==============================] - 903s 36ms/step\n",
      "\n",
      "acc: 90.23%\n",
      "---------------------------------------------------------------------\n",
      "batch: 400 neuron:75 dropout: 0.3\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 515s 34ms/step - loss: 0.5790 - acc: 0.8339\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 460s 31ms/step - loss: 0.0779 - acc: 0.9939\n",
      "10000/10000 [==============================] - 284s 28ms/step\n",
      "\n",
      "acc: 90.82%\n",
      "25000/25000 [==============================] - 703s 28ms/step\n",
      "\n",
      "acc: 89.87%\n",
      "---------------------------------------------------------------------\n",
      "batch: 400 neuron:75 dropout: 0.4\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 511s 34ms/step - loss: 0.5957 - acc: 0.8241\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 458s 31ms/step - loss: 0.0975 - acc: 0.9922\n",
      "10000/10000 [==============================] - 287s 29ms/step\n",
      "\n",
      "acc: 90.98%\n",
      "25000/25000 [==============================] - 694s 28ms/step\n",
      "\n",
      "acc: 90.16%\n",
      "---------------------------------------------------------------------\n",
      "batch: 400 neuron:75 dropout: 0.5\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 465s 31ms/step - loss: 0.5922 - acc: 0.8231\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 461s 31ms/step - loss: 0.0965 - acc: 0.9907\n",
      "10000/10000 [==============================] - 295s 30ms/step\n",
      "\n",
      "acc: 90.90%\n",
      "25000/25000 [==============================] - 680s 27ms/step\n",
      "\n",
      "acc: 90.16%\n",
      "---------------------------------------------------------------------\n",
      "batch: 500 neuron:100 dropout: 0.3\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 543s 36ms/step - loss: 0.5999 - acc: 0.7798\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 517s 34ms/step - loss: 0.1046 - acc: 0.9917\n",
      "10000/10000 [==============================] - 322s 32ms/step\n",
      "\n",
      "acc: 91.14%\n",
      "25000/25000 [==============================] - 799s 32ms/step\n",
      "\n",
      "acc: 89.94%\n",
      "---------------------------------------------------------------------\n",
      "batch: 500 neuron:100 dropout: 0.4\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 539s 36ms/step - loss: 0.6009 - acc: 0.7839\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 492s 33ms/step - loss: 0.1071 - acc: 0.9931\n",
      "10000/10000 [==============================] - 328s 33ms/step\n",
      "\n",
      "acc: 90.99%\n",
      "25000/25000 [==============================] - 813s 33ms/step\n",
      "\n",
      "acc: 89.90%\n",
      "---------------------------------------------------------------------\n",
      "batch: 500 neuron:100 dropout: 0.5\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 537s 36ms/step - loss: 0.6083 - acc: 0.8225\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 524s 35ms/step - loss: 0.1231 - acc: 0.9915\n",
      "10000/10000 [==============================] - 329s 33ms/step\n",
      "\n",
      "acc: 90.90%\n",
      "25000/25000 [==============================] - 811s 32ms/step\n",
      "\n",
      "acc: 90.03%\n",
      "---------------------------------------------------------------------\n",
      "batch: 500 neuron:75 dropout: 0.3\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 452s 30ms/step - loss: 0.6212 - acc: 0.7223\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 441s 29ms/step - loss: 0.1745 - acc: 0.9905\n",
      "10000/10000 [==============================] - 285s 29ms/step\n",
      "\n",
      "acc: 90.63%\n",
      "25000/25000 [==============================] - 715s 29ms/step\n",
      "\n",
      "acc: 89.77%\n",
      "---------------------------------------------------------------------\n",
      "batch: 500 neuron:75 dropout: 0.4\n",
      "Epoch 1/2\n",
      "15000/15000 [==============================] - 452s 30ms/step - loss: 0.6235 - acc: 0.8195\n",
      "Epoch 2/2\n",
      "15000/15000 [==============================] - 464s 31ms/step - loss: 0.1687 - acc: 0.9887\n",
      "10000/10000 [==============================] - 275s 28ms/step\n",
      "\n",
      "acc: 90.85%\n",
      "  416/25000 [..............................] - ETA: 10:47"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4c1510d30204>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n%s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m                                          steps=steps)\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size_list = [400, 500]\n",
    "neuron_list = [100, 75] #hidden neurons\n",
    "dropout_list = [0.3, 0.4, 0.5]\n",
    "\n",
    "best_score = 0\n",
    "best_batch = 0\n",
    "best_neuron = 0\n",
    "best_dropout = 0\n",
    "\n",
    "for batch in batch_size_list:\n",
    "    for neuron in neuron_list:\n",
    "        for dropout in dropout_list:\n",
    "            print('---------------------------------------------------------------------')\n",
    "            print('batch: ' + str(batch) + ' neuron:' + str(neuron) + ' dropout: ' + str(dropout))\n",
    "            input_dim = len(vectorizer.vocabulary_)\n",
    "            model = Sequential()\n",
    "            model.add(Dense(neuron, input_dim=input_dim, activation='relu'))\n",
    "            model.add(Dense(neuron, activation='relu'))\n",
    "            model.add(Dropout(dropout))\n",
    "            model.add(Dense(2, activation='softmax'))\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            model.fit(X_train, y_train, epochs=2, batch_size=batch)\n",
    "            scores = model.evaluate(X_dev, y_dev)\n",
    "            print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "            test_scores = model.evaluate(X_test, y_test)\n",
    "            print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], test_scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
